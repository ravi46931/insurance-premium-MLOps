<!-- # Introduction
# Dataset
# Model Training
# Model Tracking
# Model Evaluation
# Model deployment -->

# Insurance Premium Prediction Application

## Overview<hr>

This is a machine learning application designed for predicting insurance premiums. The project leverages a variety of tools and frameworks to streamline data management, experiment tracking, and model deployment.

<!-- ## Demo
<hr>

![Insurance-Premium-Streamlit-App](../../insgif.gif) -->



## ğŸ› ï¸ Tools Utilized
<hr>

- **DVC (Data Version Control)**: Used for managing and versioning data pipeline.
- **Git**: Version control system for tracking code changes.
- **MLflow**: Used for tracking the model training and model evaluation.
- **GitHub Actions Server**: Used for continuous integration and deployment.
- **Dagshub**: Facilitates MLflow experiment tracking and DVC data pipeline.

## ğŸ›¢ï¸ Machine Learning Pipeline
<hr>

### Data Ingestion ğŸ“¥

The application ingests insurance premium data from the _data/insurance.csv_ data path and saves it into `artifacts/DataIngestionArtifacts`.

### Data Transformation ğŸ”§

Data undergoes transformation to prepare it for model training. Transformed data and preprocessing artifacts are saved into `artifacts/DataTransformationArtifacts`. Preprocessors are also stored in `models/`.

### Model Training ğŸ¤–

Multiple machine learning models are trained:
Linear Regression, Ridge Regression, Lasso Regression, Polynomial Regression, Random Forest,
Gradient Boosting, XGBoost, LightGBM, Catboost.
The top 4 performing models based on training metrics are selected. Both models and associated metrics are saved into `artifacts/ModelTrainerArtifacts`. __MLflow__ is used to track model parameters and metrics throughout this process.

### Model Evaluation ğŸ“Š

The best-performing model on test data is selected and saved into `artifacts/ModelEvaluationArtifacts` and `models/`. Model evaluation metrics are tracked using MLflow.

### Streamlit App Development ğŸ’»

A Streamlit application is developed to allow users to input data and receive predictions from the trained model.

![img](imgs/streamlit_app.png)

### Model Deployment ğŸš€

The model is deployend on the __AWS EC2__ using __Docker__ and __Github Action Server__.

## ğŸ“‹ Model tracking with MLFlow
<hr>

![img](imgs/mlflow_exp.png)

## ğŸ–‡ï¸ Data pipeline tracking with DVC
<hr> 

![dvc_up](imgs\dvc_up.png)
![dvc_up](imgs\dvc_down.png)


## ğŸ“ Directory Structure
<hr>

```bash
ğŸ“‚.github/
â””â”€â”€ ğŸ“‚workflows/
      â””â”€â”€ main.yaml
ğŸ“‚docs/
â”œâ”€â”€ ğŸ“‚docs/
â”‚     â”œâ”€â”€ index.md
â”‚     â””â”€â”€ getting-started.md
â”œâ”€â”€ mkdocs.yml
â””â”€â”€ README.md
ğŸ“‚src/
â”œâ”€â”€ init.py
â”œâ”€â”€ ğŸ“‚components/
â”‚     â”œâ”€â”€ init.py
â”‚     â”œâ”€â”€ data_ingestion.py
â”‚     â”œâ”€â”€ data_transformation.py
â”‚     â”œâ”€â”€ model_trainer.py
â”‚     â””â”€â”€ model_evaluation.py
â”œâ”€â”€ ğŸ“‚constants/
â”‚     â””â”€â”€ init.py
â”œâ”€â”€ ğŸ“‚entity/
â”‚     â”œâ”€â”€ init.py
â”‚     â”œâ”€â”€ config_entity.py
â”‚     â””â”€â”€ artifact_entity.py
â”œâ”€â”€ ğŸ“‚pipeline/
â”‚     â”œâ”€â”€ init.py
â”‚     â”œâ”€â”€ training_pipeline.py
â”‚     â””â”€â”€ prediction_pipeline.py
â”œâ”€â”€ ğŸ“‚utils/
â”‚     â”œâ”€â”€ init.py
â”‚     â””â”€â”€ utils.py
â”œâ”€â”€ ğŸ“‚logger/
â”‚     â””â”€â”€ init.py
â””â”€â”€ ğŸ“‚exception/
      â””â”€â”€ init.py
ğŸ“‚data/
  â””â”€â”€ insurance.csv
ğŸ“‚experiment/
  â””â”€â”€ experiments.ipynb
requirements.txt
requirements_app.txt
setup.py
app.py
main.py
README.md
implement.md
.gitignore
template.py
prediction.py
init_setup.ps1
dvc.yaml
Dockerfile
demo.py
config.json
.dockerignore
.dvcignore
```

## ğŸ“ˆ Models 
<hr>

- Linear Regression 
- Ridge Regression 
- Lasso Regression 
- Polynomial Regression 
- Random Forest
- Gradient Boosting
- XGBoost 
- LightGBM 
- Catboost


## ğŸ–¥ï¸ Installation
<hr>

### ğŸ› ï¸ Requirements: 

- Python 3.10
- mkdocs
- dvc
- numpy 
- pandas
- colorama
- mlflow==2.2.2
- dagshub
- scikit-learn
- xgboost
- lightgbm
- catboost
- streamlit


## âš™ï¸ Setup
<hr>
To reproduce the model and run the application:

1. Clone the repository:
    
    `git clone <repository_url>`<br>
    `cd <repository_name>`
    
2. Set up the virtual environment and install the requirements:

    `./init_setup.ps1`<br>

3. Execute the whole pipeline:

    `python main.py`<br>
    Now run the streamlit app.


## ğŸ¯ Inference demo
<hr>

1. Run the Streamlit app:

    `streamlit run app.py`
2. Enter the input values and get prediction

## Contributors ğŸ‘¨ğŸ¼â€ğŸ’»
<hr>
- Ravi Kumar